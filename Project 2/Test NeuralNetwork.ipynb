{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-29T09:33:38.425923700Z",
     "start_time": "2023-10-29T09:33:37.925977Z"
    }
   },
   "outputs": [],
   "source": [
    "from NeuralNetwork import Neural_Network\n",
    "import numpy as np\n",
    "import jax.numpy as jnp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec891228226aa63c",
   "metadata": {},
   "source": [
    "## Initiate neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3a4c91e7bd67ea",
   "metadata": {},
   "source": [
    "1. Set up the design matrix with the inputs as discussed above and a vector containing the output, the so-called targets. Note that the design matrix is the same for all gates. You need just to define different outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8f56b6ba6623f14b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-29T09:33:38.522043300Z",
     "start_time": "2023-10-29T09:33:38.430279200Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(1234)\n",
    "\n",
    "# Create design matrix\n",
    "X = jnp.array([[0, 0],\n",
    "               [0, 1],\n",
    "               [1, 0],\n",
    "               [1, 1]])\n",
    "\n",
    "X = jnp.array([[0, 1]])\n",
    "\n",
    "# The XOR gate\n",
    "target_XOR = jnp.array( [ 0, 1 ,1, 0])\n",
    "# The OR gate\n",
    "target_OR = jnp.array( [ 0, 1 ,1, 1])\n",
    "# The AND gate\n",
    "target_AND = jnp.array( [ 0, 0 ,0, 1])\n",
    "\n",
    "target = jnp.array([0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339a0c6e2a4febd7",
   "metadata": {},
   "source": [
    "2. Construct a neural network with only one hidden layer and two hidden nodes using the Sigmoid function as activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c2f098900ba9f2a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-29T09:33:38.523045400Z",
     "start_time": "2023-10-29T09:33:38.517403500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Neural Network with 1 hidden layers and [2] nodes per layer. The activation function is sigmoid.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_hidden_layers = 1\n",
    "n_hidden_nodes = 2\n",
    "n_outputs = 1\n",
    "learning_rate=0.1\n",
    "\n",
    "ffnn = Neural_Network(X, target, n_hidden_layers, n_hidden_nodes, n_outputs, \n",
    "                      learning_rate, activation_function='sigmoid',\n",
    "                      classification_problem=True)\n",
    "\n",
    "str(ffnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285abc1b97084f53",
   "metadata": {},
   "source": [
    "3. Set up the output layer with only one output node and use again the Sigmoid function as activation function for the output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f54e143b8e4c3b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f3a8fdd8984ecbd8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-29T09:33:38.535457Z",
     "start_time": "2023-10-29T09:33:38.523557600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output layer has 1 node and uses the sigmoid as activation function\n"
     ]
    }
   ],
   "source": [
    "print(f'Output layer has {ffnn.output_layer.n_nodes} node and uses the {str(ffnn.output_layer.activation_function)} as activation function')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d066a4645a122bc",
   "metadata": {},
   "source": [
    "4. Initialize the weights and biases and perform a feed forward pass and compare the outputs with the targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d767c0df481cde5b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-29T09:33:38.571821200Z",
     "start_time": "2023-10-29T09:33:38.534432900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights hidden layer 1:\n",
      "[[ 0.04714352 -0.11909757]\n",
      " [ 0.1432707  -0.03126519]]\n",
      "Biases hidden layer 1:\n",
      "[[0.01 0.01]]\n",
      "weights output layer:\n",
      "[[-0.07205887]\n",
      " [ 0.08871629]]\n",
      "Biases output layer:\n",
      "[[0.01]]\n"
     ]
    }
   ],
   "source": [
    "print('Weights hidden layer 1:\\n'\n",
    "      f'{ffnn.hidden_layers[0].weights}')\n",
    "print('Biases hidden layer 1:\\n'\n",
    "      f'{ffnn.hidden_layers[0].biases}')\n",
    "\n",
    "print('weights output layer:\\n'\n",
    "      f'{ffnn.output_layer.weights}')\n",
    "print('Biases output layer:\\n'\n",
    "      f'{ffnn.output_layer.biases}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "442bf7331f27ac00",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-29T09:33:39.643036100Z",
     "start_time": "2023-10-29T09:33:39.567478500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final prediction before training:\n",
      "[[1.]]\n"
     ]
    }
   ],
   "source": [
    "ffnn.feed_forward()\n",
    "\n",
    "print(\"Final prediction before training:\\n\"\n",
    "      f\"{ffnn.output_layer.output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548e9e24",
   "metadata": {},
   "source": [
    "5. Set up the cost function (cross entropy for classification of binary cases).\n",
    "\n",
    "6. Calculate the gradients needed for the back propagation part.\n",
    "\n",
    "7. Use the gradients to train the network in the back propagation part. Think of using automatic differentiation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "11e8a07f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights and biases after one backward propagation: \n",
      "\n",
      "Weights hidden layer 1:\n",
      "[[ 4.71435164e-02 -1.19097569e-01]\n",
      " [ 8.35989224e+13  7.72768179e+13]]\n",
      "Biases hidden layer 1:\n",
      "[[8.35989224e+13 7.72768179e+13]]\n",
      "weights output layer:\n",
      "[[-13455304.07205887]\n",
      " [-12366392.71128371]]\n",
      "Biases output layer:\n",
      "[[-24998576.]]\n"
     ]
    }
   ],
   "source": [
    "ffnn.feed_backward()\n",
    "\n",
    "print('Weights and biases after one backward propagation: \\n')\n",
    "\n",
    "print('Weights hidden layer 1:\\n'\n",
    "      f'{ffnn.hidden_layers[0].weights}')\n",
    "print('Biases hidden layer 1:\\n'\n",
    "      f'{ffnn.hidden_layers[0].biases}')\n",
    "\n",
    "print('weights output layer:\\n'\n",
    "      f'{ffnn.output_layer.weights}')\n",
    "print('Biases output layer:\\n'\n",
    "      f'{ffnn.output_layer.biases}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245e1613",
   "metadata": {},
   "source": [
    "8. Train the network and study your results and compare with results obtained either with scikit-learn or TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f8bfa5e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vildesn\\FYS_STK_4155\\Projects\\Project 2\\activation_functions.py:33: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights and biases after training: \n",
      "\n",
      "Weights hidden layer 1:\n",
      "[[ 4.71435164e-02 -1.19097569e-01]\n",
      " [ 8.35989224e+13  7.72768179e+13]]\n",
      "Biases hidden layer 1:\n",
      "[[8.35989224e+13 7.72768179e+13]]\n",
      "weights output layer:\n",
      "[[-13455304.07205887]\n",
      " [-12366392.71128371]]\n",
      "Biases output layer:\n",
      "[[-24998576.]]\n",
      "\n",
      "Final prediction after training:\n",
      "[[0.]]\n"
     ]
    }
   ],
   "source": [
    "ffnn.train()\n",
    "\n",
    "print('Weights and biases after training: \\n')\n",
    "\n",
    "print('Weights hidden layer 1:\\n'\n",
    "      f'{ffnn.hidden_layers[0].weights}')\n",
    "print('Biases hidden layer 1:\\n'\n",
    "      f'{ffnn.hidden_layers[0].biases}')\n",
    "\n",
    "print('weights output layer:\\n'\n",
    "      f'{ffnn.output_layer.weights}')\n",
    "print('Biases output layer:\\n'\n",
    "      f'{ffnn.output_layer.biases}')\n",
    "\n",
    "print(\"\\nFinal prediction after training:\\n\"\n",
    "      f\"{ffnn.output_layer.output}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734f1a27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
