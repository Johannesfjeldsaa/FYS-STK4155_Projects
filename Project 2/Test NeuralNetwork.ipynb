{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-31T18:56:45.772510900Z",
     "start_time": "2023-10-31T18:56:45.243249800Z"
    }
   },
   "outputs": [],
   "source": [
    "from NeuralNetwork import Neural_Network\n",
    "import numpy as np\n",
    "import jax.numpy as jnp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec891228226aa63c",
   "metadata": {},
   "source": [
    "## Initiate neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3a4c91e7bd67ea",
   "metadata": {},
   "source": [
    "1. Set up the design matrix with the inputs as discussed above and a vector containing the output, the so-called targets. Note that the design matrix is the same for all gates. You need just to define different outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f56b6ba6623f14b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-31T18:56:48.178747500Z",
     "start_time": "2023-10-31T18:56:48.105480200Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(1234)\n",
    "\n",
    "# Create design matrix\n",
    "X = jnp.array([[0, 0],\n",
    "               [0, 1],\n",
    "               [1, 0],\n",
    "               [1, 1]])\n",
    "\n",
    "# The XOR gate\n",
    "target_XOR = jnp.array( [ 0, 1 ,1, 0])\n",
    "# The OR gate\n",
    "target_OR = jnp.array( [ 0, 1 ,1, 1])\n",
    "# The AND gate\n",
    "target_AND = jnp.array( [ 0, 0 ,0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339a0c6e2a4febd7",
   "metadata": {},
   "source": [
    "2. Construct a neural network with only one hidden layer and two hidden nodes using the Sigmoid function as activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2f098900ba9f2a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-31T18:56:51.918050800Z",
     "start_time": "2023-10-31T18:56:51.908101800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'Neural Network with 1 hidden layers and [2] nodes per layer. The activation function is sigmoid.'"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_hidden_layers = 1\n",
    "n_hidden_nodes = 2\n",
    "n_outputs = 1\n",
    "\n",
    "ffnn = Neural_Network(X, target_OR, n_hidden_layers, n_hidden_nodes, n_outputs, activation_function='sigmoid')\n",
    "str(ffnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285abc1b97084f53",
   "metadata": {},
   "source": [
    "3. Set up the output layer with only one output node and use again the Sigmoid function as activation function for the output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f54e143b8e4c3b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3a8fdd8984ecbd8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-29T09:33:38.535457Z",
     "start_time": "2023-10-29T09:33:38.523557600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output layer has 1 node and uses the sigmoid as activation function\n"
     ]
    }
   ],
   "source": [
    "print(f'Output layer has {ffnn.output_layer.n_nodes} node and uses the {str(ffnn.output_layer.activation_function)} as activation function')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d066a4645a122bc",
   "metadata": {},
   "source": [
    "4. Initialize the weights and biases and perform a feed forward pass and compare the outputs with the targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d767c0df481cde5b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-29T09:33:38.571821200Z",
     "start_time": "2023-10-29T09:33:38.534432900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights hidden layer 1:\n",
      "[[ 0.04714352 -0.11909757]\n",
      " [ 0.1432707  -0.03126519]]\n",
      "Biases hidden layer 1:\n",
      "[[0.01 0.01]]\n",
      "weights output layer:\n",
      "[[-0.07205887]\n",
      " [ 0.08871629]]\n",
      "Biases output layer:\n",
      "[[0.01]]\n"
     ]
    }
   ],
   "source": [
    "print('Weights hidden layer 1:\\n'\n",
    "      f'{ffnn.hidden_layers[0].weights}')\n",
    "print('Biases hidden layer 1:\\n'\n",
    "      f'{ffnn.hidden_layers[0].biases}')\n",
    "\n",
    "print('weights output layer:\\n'\n",
    "      f'{ffnn.output_layer.weights}')\n",
    "print('Biases output layer:\\n'\n",
    "      f'{ffnn.output_layer.biases}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "442bf7331f27ac00",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-29T09:33:39.643036100Z",
     "start_time": "2023-10-29T09:33:39.567478500Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "dot_general requires contracting dimensions to have the same shape, got (4,) and (2,).",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[6], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mffnn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfeed_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mWeights hidden layer 1:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m      3\u001B[0m       \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mffnn\u001B[38;5;241m.\u001B[39mhidden_layers[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mweights\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mBiases hidden layer 1:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m      5\u001B[0m       \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mffnn\u001B[38;5;241m.\u001B[39mhidden_layers[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mbiases\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[1;32m~\\FYS_STK_4155\\Projects\\Project 2\\NeuralNetwork.py:153\u001B[0m, in \u001B[0;36mNeural_Network.feed_forward\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    151\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_hidden_layers):\n\u001B[0;32m    152\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m i \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m--> 153\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhidden_layers\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward_propagation\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    154\u001B[0m         \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhidden_layers[i]\u001B[38;5;241m.\u001B[39moutput)\n\u001B[0;32m    155\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[1;32m~\\FYS_STK_4155\\Projects\\Project 2\\NeuralNetwork.py:38\u001B[0m, in \u001B[0;36mDense_Layer.forward_propagation\u001B[1;34m(self, inputs)\u001B[0m\n\u001B[0;32m     32\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward_propagation\u001B[39m(\u001B[38;5;28mself\u001B[39m, inputs):\n\u001B[0;32m     33\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     34\u001B[0m \u001B[38;5;124;03m    Forward propagation of the network.\u001B[39;00m\n\u001B[0;32m     35\u001B[0m \u001B[38;5;124;03m    :param inputs: Input data\u001B[39;00m\n\u001B[0;32m     36\u001B[0m \u001B[38;5;124;03m    :return: Output of the layer\u001B[39;00m\n\u001B[0;32m     37\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m---> 38\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutput \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mactivation_function\u001B[38;5;241m.\u001B[39mactivation_function(\u001B[43mjnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdot\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mT\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweights\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbiases)\n\u001B[0;32m     39\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutput\n",
      "    \u001B[1;31m[... skipping hidden 12 frame]\u001B[0m\n",
      "File \u001B[1;32m~\\Anaconda3\\envs\\fysstk4155\\lib\\site-packages\\jax\\_src\\numpy\\lax_numpy.py:3122\u001B[0m, in \u001B[0;36mdot\u001B[1;34m(a, b, precision, preferred_element_type)\u001B[0m\n\u001B[0;32m   3120\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   3121\u001B[0m     contract_dims \u001B[38;5;241m=\u001B[39m ((a_ndim \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m,), (b_ndim \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m2\u001B[39m,))\n\u001B[1;32m-> 3122\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[43mlax\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdot_general\u001B[49m\u001B[43m(\u001B[49m\u001B[43ma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mb\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdimension_numbers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcontract_dims\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_dims\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3123\u001B[0m \u001B[43m                           \u001B[49m\u001B[43mprecision\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprecision\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpreferred_element_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpreferred_element_type\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3124\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m lax_internal\u001B[38;5;241m.\u001B[39m_convert_element_type(result, preferred_element_type, output_weak_type)\n",
      "    \u001B[1;31m[... skipping hidden 7 frame]\u001B[0m\n",
      "File \u001B[1;32m~\\Anaconda3\\envs\\fysstk4155\\lib\\site-packages\\jax\\_src\\lax\\lax.py:2572\u001B[0m, in \u001B[0;36m_dot_general_shape_rule\u001B[1;34m(lhs, rhs, dimension_numbers, precision, preferred_element_type)\u001B[0m\n\u001B[0;32m   2569\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m core\u001B[38;5;241m.\u001B[39mdefinitely_equal_shape(lhs_contracting_shape, rhs_contracting_shape):\n\u001B[0;32m   2570\u001B[0m   msg \u001B[38;5;241m=\u001B[39m (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdot_general requires contracting dimensions to have the same \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   2571\u001B[0m          \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mshape, got \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m and \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m-> 2572\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(msg\u001B[38;5;241m.\u001B[39mformat(lhs_contracting_shape, rhs_contracting_shape))\n\u001B[0;32m   2574\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m _dot_general_shape_computation(lhs\u001B[38;5;241m.\u001B[39mshape, rhs\u001B[38;5;241m.\u001B[39mshape, dimension_numbers)\n",
      "\u001B[1;31mTypeError\u001B[0m: dot_general requires contracting dimensions to have the same shape, got (4,) and (2,)."
     ]
    }
   ],
   "source": [
    "ffnn.feed_forward()\n",
    "print('Weights hidden layer 1:\\n'\n",
    "      f'{ffnn.hidden_layers[0].weights}')\n",
    "print('Biases hidden layer 1:\\n'\n",
    "      f'{ffnn.hidden_layers[0].biases}')\n",
    "\n",
    "print('weights output layer:\\n'\n",
    "      f'{ffnn.output_layer.weights}')\n",
    "print('Biases output layer:\\n'\n",
    "      f'{ffnn.output_layer.biases}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
