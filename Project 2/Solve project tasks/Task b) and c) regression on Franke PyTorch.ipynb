{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# NN Regression on Franke Function using Pytorch "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "56f38f0dcdf97724"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Import libraries"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b77bc5535d58a8fa"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-13T09:26:23.964616300Z",
     "start_time": "2023-11-13T09:26:23.961378700Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the 'src' directory to the Python path\n",
    "src_dir = os.path.join(os.path.dirname(os.getcwd()), 'src')\n",
    "sys.path.append(src_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from torch import nn, optim, tensor\n",
    "from Neural_Network_with_PyTorch import Neural_Network_PyTorch\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn import linear_model\n",
    "\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "\n",
    "seed = 1234\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T09:27:50.081151Z",
     "start_time": "2023-11-13T09:27:43.921619500Z"
    }
   },
   "id": "66ae3b87ef963254"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create Data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8ec8566c7e016202"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def FrankeFunction(x,y):\n",
    "    \n",
    "    term1 = 0.75*np.exp(-(0.25*(9*x-2)**2) - 0.25*((9*y-2)**2))\n",
    "    term2 = 0.75*np.exp(-((9*x+1)**2)/49.0 - 0.1*(9*y+1))\n",
    "    term3 = 0.5*np.exp(-(9*x-7)**2/4.0 - 0.25*((9*y-3)**2))\n",
    "    term4 = -0.2*np.exp(-(9*x-4)**2 - (9*y-7)**2)\n",
    "    return term1 + term2 + term3 + term4"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T09:52:26.897366100Z",
     "start_time": "2023-11-13T09:52:26.879212Z"
    }
   },
   "id": "3eaeb63ce77c9151"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0.5400, 0.6865],\n        [0.3597, 0.8124],\n        [0.4005, 0.8476],\n        ...,\n        [0.6594, 0.7230],\n        [0.2349, 0.2420],\n        [0.4470, 0.9988]])"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 1000\n",
    "x = np.random.uniform(0, 1, N)\n",
    "y = np.random.uniform(0, 1, N)\n",
    "\n",
    "# Franke function with added noise:\n",
    "z = FrankeFunction(x, y) + np.random.normal(0, 0.1, x.shape)\n",
    "target = torch.tensor(z).reshape(len(z), 1)\n",
    "\n",
    "# Making the design matrix:\n",
    "X = torch.from_numpy(np.stack((x, y), axis=-1)).float()\n",
    "\n",
    "# Splitting the data into training and test set:\n",
    "test_size = 0.2\n",
    "X_train, X_test, target_train, target_test = train_test_split(X, target, test_size=test_size)\n",
    "\n",
    "X "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T10:08:46.609446500Z",
     "start_time": "2023-11-13T10:08:46.587501800Z"
    }
   },
   "id": "72cbbb2a680cbba0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tune model using K-fold cross validation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2c504909e5b082b5"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def train_with_crossval(train_X, train_target, \n",
    "                        n_features, n_hidden_layers, n_hidden_nodes, n_outputs, \n",
    "                        activation_hidden, \n",
    "                        learning_rate, l2_reg, \n",
    "                        num_epochs, n_minibatches):\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "    # Initialize the evaluation metrices\n",
    "    mse_crossval = []\n",
    "    r2_crossval = []\n",
    "    mse_train_crossval = []\n",
    "    r2_train_crossval = []\n",
    "    # Loop over the folds\n",
    "    for train_idx, val_idx in kf.split(train_X):\n",
    "        # Extract training and validation data\n",
    "        X_train, target_train = train_X[train_idx], train_target[train_idx]\n",
    "        X_val, target_val = train_X[val_idx], train_target[val_idx]\n",
    "        \n",
    "        # Create new network\n",
    "        ffnn = Neural_Network_PyTorch(n_features, \n",
    "                                      n_hidden_layers, n_hidden_nodes, \n",
    "                                      n_outputs, \n",
    "                                      activation_function_hidden_layers=activation_hidden, \n",
    "                                      activation_function_output_layer=None)\n",
    "        \n",
    "        # Loss function\n",
    "        criterion = nn.MSELoss()\n",
    "        # Optimizer\n",
    "        optimizer = optim.Adam(ffnn.parameters(), lr=learning_rate, weight_decay=l2_reg)\n",
    "        \n",
    "        # Train the network            \n",
    "        ffnn = ffnn.train_network(X_train, target_train, \n",
    "                                  optimizer, criterion,\n",
    "                                  num_iter=num_epochs, n_minibatches=n_minibatches)\n",
    "        # Evaluate the network\n",
    "        # Train performance\n",
    "        target_train_pred = ffnn.feed_forward(X_train)\n",
    "        mse_train_crossval.append(float(criterion(target_train_pred, target_train)))\n",
    "        r2_train_crossval.append(r2_score(target_train, target_train_pred.detach().numpy()))\n",
    "        # Validation performance\n",
    "        ffnn.eval() # set model in evaluation mode\n",
    "        with torch.no_grad(): # disable gradient computation\n",
    "            target_val_pred = ffnn.feed_forward(X_val)\n",
    "            mse_val_cv = float(criterion(target_val_pred, target_val))\n",
    "            mse_crossval.append(mse_val_cv)\n",
    "            r2_crossval.append(r2_score(target_val, target_val_pred))\n",
    "    \n",
    "    return ffnn, mse_crossval, r2_crossval, mse_train_crossval, r2_train_crossval"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T10:00:12.026668400Z",
     "start_time": "2023-11-13T10:00:12.013474300Z"
    }
   },
   "id": "69910daada0883ad"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Initial tuning of learning rate"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c210967fe51851ca"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a2b52a08bccab997"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "n_hidden_layers = 2\n",
    "n_hidden_nodes = 8\n",
    "n_outputs = 2\n",
    "n_features = X_train.shape[1]\n",
    "activation_hidden = \"sigmoid\"\n",
    "learning_rate_space = np.logspace(-4, 0, 5)\n",
    "lmbd = 0.0001\n",
    "n_epochs = 100\n",
    "n_minibatches = 16"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T10:06:56.086657200Z",
     "start_time": "2023-11-13T10:06:56.074701900Z"
    }
   },
   "id": "20a76932c26af83a"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.0001\n",
      "<function Neural_Network_PyTorch.set_activation_function.<locals>.dummy at 0x000001AB37645BC0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python\\envs\\DataAnalysis\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Found dtype Double but expected Float",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[23], line 9\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, learning_rate \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(learning_rate_space):\n\u001B[0;32m      7\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mLearning rate: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mlearning_rate\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m----> 9\u001B[0m     train_with_crossval(X_train, target_train, \n\u001B[0;32m     10\u001B[0m                         n_features, n_hidden_layers, n_hidden_nodes, n_outputs, \n\u001B[0;32m     11\u001B[0m                         activation_hidden, \n\u001B[0;32m     12\u001B[0m                         learning_rate, lmbd, \n\u001B[0;32m     13\u001B[0m                         n_epochs, n_minibatches)\n\u001B[0;32m     15\u001B[0m     mse[i][j] \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mmean(mse_crossval)\n\u001B[0;32m     16\u001B[0m     r2[i][j] \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mmean(r2_crossval)\n",
      "Cell \u001B[1;32mIn[15], line 31\u001B[0m, in \u001B[0;36mtrain_with_crossval\u001B[1;34m(train_X, train_target, n_features, n_hidden_layers, n_hidden_nodes, n_outputs, activation_hidden, learning_rate, l2_reg, num_epochs, n_minibatches)\u001B[0m\n\u001B[0;32m     28\u001B[0m optimizer \u001B[38;5;241m=\u001B[39m optim\u001B[38;5;241m.\u001B[39mAdam(ffnn\u001B[38;5;241m.\u001B[39mparameters(), lr\u001B[38;5;241m=\u001B[39mlearning_rate, weight_decay\u001B[38;5;241m=\u001B[39ml2_reg)\n\u001B[0;32m     30\u001B[0m \u001B[38;5;66;03m# Train the network            \u001B[39;00m\n\u001B[1;32m---> 31\u001B[0m ffnn \u001B[38;5;241m=\u001B[39m ffnn\u001B[38;5;241m.\u001B[39mtrain_network(X_train, target_train, \n\u001B[0;32m     32\u001B[0m                           optimizer, criterion,\n\u001B[0;32m     33\u001B[0m                           num_iter\u001B[38;5;241m=\u001B[39mnum_epochs, n_minibatches\u001B[38;5;241m=\u001B[39mn_minibatches)\n\u001B[0;32m     34\u001B[0m \u001B[38;5;66;03m# Evaluate the network\u001B[39;00m\n\u001B[0;32m     35\u001B[0m \u001B[38;5;66;03m# Train performance\u001B[39;00m\n\u001B[0;32m     36\u001B[0m target_train_pred \u001B[38;5;241m=\u001B[39m ffnn\u001B[38;5;241m.\u001B[39mfeed_forward(X_train)\n",
      "File \u001B[1;32mD:\\Programmering\\FYS-STK4155\\FYS-STK4155_Projects\\Project 2\\src\\Neural_Network_with_PyTorch.py:165\u001B[0m, in \u001B[0;36mNeural_Network_PyTorch.train_network\u001B[1;34m(self, X, target, optimizer, criterion, num_iter, n_minibatches)\u001B[0m\n\u001B[0;32m    163\u001B[0m \u001B[38;5;66;03m# Calculate loss and do backpropagation\u001B[39;00m\n\u001B[0;32m    164\u001B[0m loss \u001B[38;5;241m=\u001B[39m criterion(target_pred, target_batch)\n\u001B[1;32m--> 165\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[0;32m    167\u001B[0m \u001B[38;5;66;03m# Updating neural network parameters: w = w - learning_rate * gradient\u001B[39;00m\n\u001B[0;32m    168\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n",
      "File \u001B[1;32mD:\\Python\\envs\\DataAnalysis\\Lib\\site-packages\\torch\\_tensor.py:492\u001B[0m, in \u001B[0;36mTensor.backward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    482\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    483\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[0;32m    484\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[0;32m    485\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    490\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[0;32m    491\u001B[0m     )\n\u001B[1;32m--> 492\u001B[0m torch\u001B[38;5;241m.\u001B[39mautograd\u001B[38;5;241m.\u001B[39mbackward(\n\u001B[0;32m    493\u001B[0m     \u001B[38;5;28mself\u001B[39m, gradient, retain_graph, create_graph, inputs\u001B[38;5;241m=\u001B[39minputs\n\u001B[0;32m    494\u001B[0m )\n",
      "File \u001B[1;32mD:\\Python\\envs\\DataAnalysis\\Lib\\site-packages\\torch\\autograd\\__init__.py:251\u001B[0m, in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[0;32m    246\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[0;32m    248\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[0;32m    249\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[0;32m    250\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[1;32m--> 251\u001B[0m Variable\u001B[38;5;241m.\u001B[39m_execution_engine\u001B[38;5;241m.\u001B[39mrun_backward(  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[0;32m    252\u001B[0m     tensors,\n\u001B[0;32m    253\u001B[0m     grad_tensors_,\n\u001B[0;32m    254\u001B[0m     retain_graph,\n\u001B[0;32m    255\u001B[0m     create_graph,\n\u001B[0;32m    256\u001B[0m     inputs,\n\u001B[0;32m    257\u001B[0m     allow_unreachable\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[0;32m    258\u001B[0m     accumulate_grad\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[0;32m    259\u001B[0m )\n",
      "\u001B[1;31mRuntimeError\u001B[0m: Found dtype Double but expected Float"
     ]
    }
   ],
   "source": [
    "# Initialize the evaluation metrices\n",
    "mse = np.zeros((len(learning_rate_space), 1))\n",
    "r2 = np.zeros((len(learning_rate_space), 1))\n",
    "mse_train = np.zeros((len(learning_rate_space), 1))\n",
    "r2_train = np.zeros((len(learning_rate_space), 1))\n",
    "for i, learning_rate in enumerate(learning_rate_space):\n",
    "    print(f\"Learning rate: {learning_rate}\")\n",
    "    \n",
    "    train_with_crossval(X_train, target_train, \n",
    "                        n_features, n_hidden_layers, n_hidden_nodes, n_outputs, \n",
    "                        activation_hidden, \n",
    "                        learning_rate, lmbd, \n",
    "                        n_epochs, n_minibatches)\n",
    "    \n",
    "    mse[i][j] = np.mean(mse_crossval)\n",
    "    r2[i][j] = np.mean(r2_crossval)\n",
    "    mse_train[i][j] = np.mean(mse_train_crossval)\n",
    "    r2_train[i][j] = np.mean(r2_train_crossval)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T10:06:58.951871900Z",
     "start_time": "2023-11-13T10:06:58.863866900Z"
    }
   },
   "id": "c056d737cf42cd86"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Retrain model on entire training set"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "39022917cc61b36b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Estimate generalization error"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "150965d55044d13e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
