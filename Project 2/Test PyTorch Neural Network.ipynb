{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Neural Network with PyTorch framework"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "86cad4281a763db6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Import libraries"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2efef9246badaac9"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-05T19:31:49.858197900Z",
     "start_time": "2023-11-05T19:31:47.708425200Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from tqdm import tqdm\n",
    "from Neural_Network_with_PyTorch import Neural_Network_PyTorch, cost_function_PyTorch, Gradient_Descent_PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create Neural network and perform passes"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9b4d705eb5bf84d3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. Set up the design matrix with the inputs as discussed above and a vector containing the output, the so-called targets. Note that the design matrix is the same for all gates. You need just to define different outputs."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "81f52acacf316be3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "We start by defining a helper function that allows us to convert a numpy array to a PyTorch tensor, with or without the gradient flag.  "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9b7839efb5e03f7e"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Create design matrix\n",
    "X = torch.Tensor([[0, 0], [0, 1], [1, 0], [1, 1]]).requires_grad_(True)\n",
    "\n",
    "# The XOR gate\n",
    "target_XOR = torch.Tensor([ 0, 1 ,1, 0]).view(-1, 1)\n",
    "# The OR gate\n",
    "target_OR = torch.Tensor([ 0, 1 ,1, 1]).view(-1, 1)\n",
    "# The AND gate\n",
    "target_AND = torch.Tensor([ 0, 0 ,0, 1]).view(-1, 1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T19:31:49.869026200Z",
     "start_time": "2023-11-05T19:31:49.861710Z"
    }
   },
   "id": "5d6ad790cc4362ad"
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. Construct a neural network with only one hidden layer and two hidden nodes using the Sigmoid function as activation function.\n",
    "3. Set up the output layer with only one output node and use again the Sigmoid function as activation function for the output."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a28088293c725bdc"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The network has the following hidden layers:\n",
      "[[Linear(in_features=2, out_features=2, bias=True), Sigmoid()], [Linear(in_features=2, out_features=2, bias=True), Sigmoid()], [Linear(in_features=2, out_features=2, bias=True), Sigmoid()], [Linear(in_features=2, out_features=2, bias=True), Sigmoid()]]\n",
      "The network has the following output layer:\n",
      "Linear(in_features=2, out_features=1, bias=True)\n"
     ]
    }
   ],
   "source": [
    "# Network design\n",
    "n_inputs = X.shape[1]\n",
    "n_hidden_layers = 4\n",
    "n_hidden_nodes = 2\n",
    "n_outputs = 1\n",
    "\n",
    "# Create network\n",
    "ffnn = Neural_Network_PyTorch(n_inputs, \n",
    "                              n_hidden_layers, n_hidden_nodes, \n",
    "                              n_outputs, \n",
    "                              activation_function_hidden_layers='sigmoid',\n",
    "                              activation_function_output_layer='sigmoid')\n",
    "print('The network has the following hidden layers:')\n",
    "print(ffnn.hidden_layers)\n",
    "print('The network has the following output layer:')\n",
    "print(ffnn.output_layer)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T19:31:49.883782400Z",
     "start_time": "2023-11-05T19:31:49.865557600Z"
    }
   },
   "id": "1ca689bc2603bc9"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([-0.1298, -0.2608], requires_grad=True)\n",
      "Sigmoid()\n",
      "Parameter containing:\n",
      "tensor([ 0.5738, -0.6375], requires_grad=True)\n",
      "Sigmoid()\n",
      "Parameter containing:\n",
      "tensor([-0.3923, -0.5195], requires_grad=True)\n",
      "Sigmoid()\n",
      "Parameter containing:\n",
      "tensor([0.6350, 0.2233], requires_grad=True)\n",
      "Sigmoid()\n"
     ]
    }
   ],
   "source": [
    "for layer in ffnn.hidden_layers:\n",
    "    print(layer[0].bias)\n",
    "    print(layer[1])\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T19:31:49.910332900Z",
     "start_time": "2023-11-05T19:31:49.877010Z"
    }
   },
   "id": "c795cd3605117299"
  },
  {
   "cell_type": "markdown",
   "source": [
    "5. Set up the cost function (cross entropy for classification of binary cases)."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "892b3d3307d5ccd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "The evaluation criterion in this case is the cross entropy function. Therefor we create a cost function object from the cost_function_PyTorch class."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e18afac54d5b5fc6"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "'BCEWithLogitsLoss()'"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "critertion = cost_function_PyTorch('BCEWithLogitsLoss').cost_function\n",
    "str(critertion)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T19:31:49.911856900Z",
     "start_time": "2023-11-05T19:31:49.884782900Z"
    }
   },
   "id": "96c0b9516c0b3c56"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we calculate the cost function for the output of the network."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "28e93aa1992e1adf"
  },
  {
   "cell_type": "markdown",
   "source": [
    "6. Calculate the gradients needed for the back propagation part."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "47adfcb18df669fe"
  },
  {
   "cell_type": "markdown",
   "source": [
    "In order to perform the back propagation part, we need to calculate the gradients of the cost function with respect to the weights and biases. This is done by the autograd package of PyTorch. We therefor initiate an optimizer object from the Gradient_Descent_PyTorch class based on the designed neural network."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1f73aba0685d0c47"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    differentiable: False\n",
      "    foreach: None\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.01\n",
    "optimizer = Gradient_Descent_PyTorch(neural_network=ffnn,\n",
    "                                     optimiziation_method='SGD',\n",
    "                                     learning_rate=learning_rate).optimizer\n",
    "print(optimizer)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T19:31:53.124797800Z",
     "start_time": "2023-11-05T19:31:52.645253500Z"
    }
   },
   "id": "b823f2494905e0bb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "4. Perform the feed-forward pass and calculate the output of the network.\n",
    "\n",
    "7. Use the gradients to train the network in the back propagation part. Think of using automatic differentiation."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7afd3f0d2701c398"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 241/100000 [00:00<01:23, 1200.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 and Loss: 0.6931478381156921\n",
      "Epoch: 100 and Loss: 0.6931478381156921\n",
      "Epoch: 200 and Loss: 0.6931478381156921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 482/100000 [00:00<01:23, 1198.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 300 and Loss: 0.6931478381156921\n",
      "Epoch: 400 and Loss: 0.6931478381156921\n",
      "Epoch: 500 and Loss: 0.6931478381156921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 715/100000 [00:00<01:29, 1114.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 600 and Loss: 0.6931478381156921\n",
      "Epoch: 700 and Loss: 0.6931478381156921\n",
      "Epoch: 800 and Loss: 0.6931478381156921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 1052/100000 [00:00<01:29, 1100.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 900 and Loss: 0.6931478381156921\n",
      "Epoch: 1000 and Loss: 0.6931478381156921\n",
      "Epoch: 1100 and Loss: 0.6931478381156921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|▏         | 1382/100000 [00:01<01:33, 1055.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1200 and Loss: 0.6931478381156921\n",
      "Epoch: 1300 and Loss: 0.6931478381156921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 1615/100000 [00:01<01:29, 1102.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1400 and Loss: 0.6931478381156921\n",
      "Epoch: 1500 and Loss: 0.6931478381156921\n",
      "Epoch: 1600 and Loss: 0.6931478381156921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 1834/100000 [00:01<01:33, 1052.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1700 and Loss: 0.6931478381156921\n",
      "Epoch: 1800 and Loss: 0.6931478381156921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 2053/100000 [00:01<01:33, 1044.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1900 and Loss: 0.6931478381156921\n",
      "Epoch: 2000 and Loss: 0.6931478381156921\n",
      "Epoch: 2100 and Loss: 0.6931478381156921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 2375/100000 [00:02<01:33, 1049.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2200 and Loss: 0.6931478381156921\n",
      "Epoch: 2300 and Loss: 0.6931478381156921\n",
      "Epoch: 2400 and Loss: 0.6931478381156921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 2730/100000 [00:02<01:24, 1149.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2500 and Loss: 0.6931478381156921\n",
      "Epoch: 2600 and Loss: 0.6931478381156921\n",
      "Epoch: 2700 and Loss: 0.6931478381156921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 2978/100000 [00:02<01:21, 1188.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2800 and Loss: 0.6931478381156921\n",
      "Epoch: 2900 and Loss: 0.6931478381156921\n",
      "Epoch: 3000 and Loss: 0.6931478381156921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 3356/100000 [00:02<01:18, 1235.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3100 and Loss: 0.6931478381156921\n",
      "Epoch: 3200 and Loss: 0.6931478381156921\n",
      "Epoch: 3300 and Loss: 0.6931478381156921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▎         | 3606/100000 [00:03<01:17, 1242.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3400 and Loss: 0.6931478381156921\n",
      "Epoch: 3500 and Loss: 0.6931478381156921\n",
      "Epoch: 3600 and Loss: 0.6931478381156921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 3859/100000 [00:03<01:16, 1252.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3700 and Loss: 0.6931478381156921\n",
      "Epoch: 3800 and Loss: 0.6931478381156921\n",
      "Epoch: 3900 and Loss: 0.6931478381156921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 4112/100000 [00:03<01:18, 1220.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4000 and Loss: 0.6931478381156921\n",
      "Epoch: 4100 and Loss: 0.6931478381156921\n",
      "Epoch: 4200 and Loss: 0.6931478381156921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 4485/100000 [00:03<01:17, 1231.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4300 and Loss: 0.6931478381156921\n",
      "Epoch: 4400 and Loss: 0.6931478381156921\n",
      "Epoch: 4500 and Loss: 0.6931478381156921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▍         | 4868/100000 [00:04<01:15, 1257.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4600 and Loss: 0.6931478381156921\n",
      "Epoch: 4700 and Loss: 0.6931478381156921\n",
      "Epoch: 4800 and Loss: 0.6931478381156921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▌         | 5125/100000 [00:04<01:14, 1269.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4900 and Loss: 0.6931478381156921\n",
      "Epoch: 5000 and Loss: 0.6931478381156921\n",
      "Epoch: 5100 and Loss: 0.6931478381156921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▌         | 5379/100000 [00:04<01:15, 1255.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5200 and Loss: 0.6931478381156921\n",
      "Epoch: 5300 and Loss: 0.6931478381156921\n",
      "Epoch: 5400 and Loss: 0.6931478381156921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 5631/100000 [00:04<01:15, 1243.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5500 and Loss: 0.6931478381156921\n",
      "Epoch: 5600 and Loss: 0.6931478381156921\n",
      "Epoch: 5700 and Loss: 0.6931478381156921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 6012/100000 [00:05<01:15, 1249.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5800 and Loss: 0.6931478381156921\n",
      "Epoch: 5900 and Loss: 0.6931478381156921\n",
      "Epoch: 6000 and Loss: 0.6931478381156921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▋         | 6267/100000 [00:05<01:14, 1257.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6100 and Loss: 0.6931478381156921\n",
      "Epoch: 6200 and Loss: 0.6931478381156921\n",
      "Epoch: 6300 and Loss: 0.6931478381156921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 6525/100000 [00:05<01:13, 1268.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6400 and Loss: 0.6931478381156921\n",
      "Epoch: 6500 and Loss: 0.6931478381156921\n",
      "Epoch: 6600 and Loss: 0.6931478381156921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 6774/100000 [00:05<01:17, 1205.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6700 and Loss: 0.6931478381156921\n",
      "Epoch: 6800 and Loss: 0.6931478381156921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 7008/100000 [00:06<01:27, 1057.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6900 and Loss: 0.6931478381156921\n",
      "Epoch: 7000 and Loss: 0.6931478381156921\n",
      "Epoch: 7100 and Loss: 0.6931478381156921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 7332/100000 [00:06<01:29, 1039.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7200 and Loss: 0.6931478381156921\n",
      "Epoch: 7300 and Loss: 0.6931478381156921\n",
      "Epoch: 7400 and Loss: 0.6931478381156921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 7712/100000 [00:06<01:18, 1179.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7500 and Loss: 0.6931478381156921\n",
      "Epoch: 7600 and Loss: 0.6931478381156921\n",
      "Epoch: 7700 and Loss: 0.6931478381156921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 7963/100000 [00:06<01:15, 1215.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7800 and Loss: 0.6931478381156921\n",
      "Epoch: 7900 and Loss: 0.6931478381156921\n",
      "Epoch: 8000 and Loss: 0.6931478381156921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 8356/100000 [00:07<01:12, 1272.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8100 and Loss: 0.6931478381156921\n",
      "Epoch: 8200 and Loss: 0.6931478381156921\n",
      "Epoch: 8300 and Loss: 0.6931478381156921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▊         | 8613/100000 [00:07<01:11, 1269.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8400 and Loss: 0.6931478381156921\n",
      "Epoch: 8500 and Loss: 0.6931478381156921\n",
      "Epoch: 8600 and Loss: 0.6931478381156921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 8869/100000 [00:07<01:14, 1216.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8700 and Loss: 0.6931478381156921\n",
      "Epoch: 8800 and Loss: 0.6931478381156921\n",
      "Epoch: 8900 and Loss: 0.6931478381156921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 9110/100000 [00:07<01:18, 1156.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9000 and Loss: 0.6931478381156921\n",
      "Epoch: 9100 and Loss: 0.6931478381156921\n",
      "Epoch: 9200 and Loss: 0.6931478381156921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 9469/100000 [00:08<01:18, 1148.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9300 and Loss: 0.6931478381156921\n",
      "Epoch: 9400 and Loss: 0.6931478381156921\n",
      "Epoch: 9500 and Loss: 0.6931478381156921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|▉         | 9822/100000 [00:08<01:18, 1152.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9600 and Loss: 0.6931478381156921\n",
      "Epoch: 9700 and Loss: 0.6931478381156921\n",
      "Epoch: 9800 and Loss: 0.6931478381156921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 10064/100000 [00:08<01:16, 1172.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9900 and Loss: 0.6931478381156921\n",
      "Epoch: 10000 and Loss: 0.6931478381156921\n",
      "Epoch: 10100 and Loss: 0.6931478381156921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 10317/100000 [00:08<01:13, 1216.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10200 and Loss: 0.6931478381156921\n",
      "Epoch: 10300 and Loss: 0.6931478381156921\n",
      "Epoch: 10400 and Loss: 0.6931478381156921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 10693/100000 [00:09<01:12, 1234.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10500 and Loss: 0.6931478381156921\n",
      "Epoch: 10600 and Loss: 0.6931478381156921\n",
      "Epoch: 10700 and Loss: 0.6931478381156921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 10948/100000 [00:09<01:14, 1201.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10800 and Loss: 0.6931478381156921\n",
      "Epoch: 10900 and Loss: 0.6931478381156921\n",
      "Epoch: 11000 and Loss: 0.6931478381156921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█▏        | 11328/100000 [00:09<01:11, 1240.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11100 and Loss: 0.6931478381156921\n",
      "Epoch: 11200 and Loss: 0.6931478381156921\n",
      "Epoch: 11300 and Loss: 0.6931478381156921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 11588/100000 [00:09<01:09, 1265.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11400 and Loss: 0.6931478381156921\n",
      "Epoch: 11500 and Loss: 0.6931478381156921\n",
      "Epoch: 11600 and Loss: 0.6931478381156921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 11845/100000 [00:10<01:11, 1231.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11700 and Loss: 0.6931478381156921\n",
      "Epoch: 11800 and Loss: 0.6931478381156921\n",
      "Epoch: 11900 and Loss: 0.6931478381156921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 12232/100000 [00:10<01:09, 1261.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12000 and Loss: 0.6931478381156921\n",
      "Epoch: 12100 and Loss: 0.6931478381156921\n",
      "Epoch: 12200 and Loss: 0.6931478381156921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 12497/100000 [00:10<01:07, 1293.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12300 and Loss: 0.6931478381156921\n",
      "Epoch: 12400 and Loss: 0.6931478381156921\n",
      "Epoch: 12500 and Loss: 0.6931478381156921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 12761/100000 [00:10<01:06, 1304.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12600 and Loss: 0.6931478381156921\n",
      "Epoch: 12700 and Loss: 0.6931478381156921\n",
      "Epoch: 12800 and Loss: 0.6931478381156921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 13022/100000 [00:10<01:11, 1218.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12900 and Loss: 0.6931478381156921\n",
      "Epoch: 13000 and Loss: 0.6931478381156921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 13261/100000 [00:11<01:18, 1104.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13100 and Loss: 0.6931478381156921\n",
      "Epoch: 13200 and Loss: 0.6931478381156921\n",
      "Epoch: 13300 and Loss: 0.6931478381156921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▎        | 13502/100000 [00:11<01:17, 1122.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13400 and Loss: 0.6931478381156921\n",
      "Epoch: 13500 and Loss: 0.6931478381156921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▎        | 13728/100000 [00:11<01:18, 1094.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13600 and Loss: 0.6931478381156921\n",
      "Epoch: 13700 and Loss: 0.6931478381156921\n",
      "Epoch: 13800 and Loss: 0.6931478381156921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 13986/100000 [00:11<01:12, 1189.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13900 and Loss: 0.6931478381156921\n",
      "Epoch: 14000 and Loss: 0.6931478381156921\n",
      "Epoch: 14100 and Loss: 0.6931478381156921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 14322/100000 [00:12<01:26, 989.90it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14200 and Loss: 0.6931478381156921\n",
      "Epoch: 14300 and Loss: 0.6931478381156921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▍        | 14547/100000 [00:12<01:24, 1016.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14400 and Loss: 0.6931478381156921\n",
      "Epoch: 14500 and Loss: 0.6931478381156921\n",
      "Epoch: 14600 and Loss: 0.6931478381156921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▍        | 14911/100000 [00:12<01:14, 1148.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14700 and Loss: 0.6931478381156921\n",
      "Epoch: 14800 and Loss: 0.6931478381156921\n",
      "Epoch: 14900 and Loss: 0.6931478381156921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▌        | 15182/100000 [00:12<01:08, 1245.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 and Loss: 0.6931478381156921\n",
      "Epoch: 15100 and Loss: 0.6931478381156921\n",
      "Epoch: 15200 and Loss: 0.6931478381156921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▌        | 15434/100000 [00:13<01:08, 1240.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15300 and Loss: 0.6931478381156921\n",
      "Epoch: 15400 and Loss: 0.6931478381156921\n",
      "Epoch: 15500 and Loss: 0.6931478381156921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▌        | 15800/100000 [00:13<01:11, 1181.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15600 and Loss: 0.6931478381156921\n",
      "Epoch: 15700 and Loss: 0.6931478381156921\n",
      "Epoch: 15800 and Loss: 0.6931478381156921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▌        | 16064/100000 [00:13<01:07, 1244.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15900 and Loss: 0.6931478381156921\n",
      "Epoch: 16000 and Loss: 0.6931478381156921\n",
      "Epoch: 16100 and Loss: 0.6931478381156921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▋        | 16313/100000 [00:13<01:10, 1186.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16200 and Loss: 0.6931478381156921\n",
      "Epoch: 16300 and Loss: 0.6931478381156921\n",
      "Epoch: 16400 and Loss: 0.6931478381156921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 16696/100000 [00:14<01:07, 1237.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16500 and Loss: 0.6931478381156921\n",
      "Epoch: 16600 and Loss: 0.6931478381156921\n",
      "Epoch: 16700 and Loss: 0.6931478381156921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 16967/100000 [00:14<01:03, 1297.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16800 and Loss: 0.6931478381156921\n",
      "Epoch: 16900 and Loss: 0.6931478381156921\n",
      "Epoch: 17000 and Loss: 0.6931478381156921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 17235/100000 [00:14<01:03, 1305.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17100 and Loss: 0.6931478381156921\n",
      "Epoch: 17200 and Loss: 0.6931478381156921\n",
      "Epoch: 17300 and Loss: 0.6931478381156921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 17645/100000 [00:14<01:01, 1332.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17400 and Loss: 0.6931478381156921\n",
      "Epoch: 17500 and Loss: 0.6931478381156921\n",
      "Epoch: 17600 and Loss: 0.6931478381156921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 17913/100000 [00:15<01:01, 1328.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17700 and Loss: 0.6931478381156921\n",
      "Epoch: 17800 and Loss: 0.6931478381156921\n",
      "Epoch: 17900 and Loss: 0.6931478381156921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 18182/100000 [00:15<01:01, 1334.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18000 and Loss: 0.6931478381156921\n",
      "Epoch: 18100 and Loss: 0.6931478381156921\n",
      "Epoch: 18200 and Loss: 0.6931478381156921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 18450/100000 [00:15<01:02, 1304.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18300 and Loss: 0.6931478381156921\n",
      "Epoch: 18400 and Loss: 0.6931478381156921\n",
      "Epoch: 18500 and Loss: 0.6931478381156921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▊        | 18716/100000 [00:15<01:02, 1306.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18600 and Loss: 0.6931478381156921\n",
      "Epoch: 18700 and Loss: 0.6931478381156921\n",
      "Epoch: 18800 and Loss: 0.6931478381156921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▉        | 19102/100000 [00:16<01:05, 1236.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18900 and Loss: 0.6931478381156921\n",
      "Epoch: 19000 and Loss: 0.6931478381156921\n",
      "Epoch: 19100 and Loss: 0.6931478381156921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▉        | 19350/100000 [00:16<01:06, 1203.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19200 and Loss: 0.6931478381156921\n",
      "Epoch: 19300 and Loss: 0.6931478381156921\n",
      "Epoch: 19400 and Loss: 0.6931478381156921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|█▉        | 19758/100000 [00:16<01:01, 1304.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19500 and Loss: 0.6931478381156921\n",
      "Epoch: 19600 and Loss: 0.6931478381156921\n",
      "Epoch: 19700 and Loss: 0.6931478381156921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|██        | 20024/100000 [00:16<01:01, 1303.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19800 and Loss: 0.6931478381156921\n",
      "Epoch: 19900 and Loss: 0.6931478381156921\n",
      "Epoch: 20000 and Loss: 0.6931478381156921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|██        | 20294/100000 [00:16<01:00, 1312.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20100 and Loss: 0.6931478381156921\n",
      "Epoch: 20200 and Loss: 0.6931478381156921\n",
      "Epoch: 20300 and Loss: 0.6931478381156921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  21%|██        | 20558/100000 [00:17<01:00, 1309.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20400 and Loss: 0.6931478381156921\n",
      "Epoch: 20500 and Loss: 0.6931478381156921\n",
      "Epoch: 20600 and Loss: 0.6931478381156921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  21%|██        | 20961/100000 [00:17<00:59, 1321.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20700 and Loss: 0.6931478381156921\n",
      "Epoch: 20800 and Loss: 0.6931478381156921\n",
      "Epoch: 20900 and Loss: 0.6931478381156921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  21%|██        | 21233/100000 [00:17<00:59, 1322.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21000 and Loss: 0.6931478381156921\n",
      "Epoch: 21100 and Loss: 0.6931478381156921\n",
      "Epoch: 21200 and Loss: 0.6931478381156921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  21%|██▏       | 21494/100000 [00:17<01:04, 1226.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21300 and Loss: 0.6931478381156921\n",
      "Epoch: 21400 and Loss: 0.6931478381156921\n",
      "Epoch: 21500 and Loss: 0.6931478381156921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  22%|██▏       | 21763/100000 [00:18<01:01, 1282.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21600 and Loss: 0.6931478381156921\n",
      "Epoch: 21700 and Loss: 0.6931478381156921\n",
      "Epoch: 21800 and Loss: 0.6931478381156921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  22%|██▏       | 22031/100000 [00:18<01:02, 1254.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21900 and Loss: 0.6931478381156921\n",
      "Epoch: 22000 and Loss: 0.6931478381156921\n",
      "Epoch: 22100 and Loss: 0.6931478381156921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  22%|██▏       | 22424/100000 [00:18<01:00, 1273.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22200 and Loss: 0.6931478381156921\n",
      "Epoch: 22300 and Loss: 0.6931478381156921\n",
      "Epoch: 22400 and Loss: 0.6931478381156921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  23%|██▎       | 22683/100000 [00:18<01:00, 1269.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22500 and Loss: 0.6931478381156921\n",
      "Epoch: 22600 and Loss: 0.6931478381156921\n",
      "Epoch: 22700 and Loss: 0.6931478381156921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  23%|██▎       | 22939/100000 [00:19<01:03, 1209.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22800 and Loss: 0.6931478381156921\n",
      "Epoch: 22900 and Loss: 0.6931478381156921\n",
      "Epoch: 23000 and Loss: 0.6931478381156921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  23%|██▎       | 23328/100000 [00:19<01:00, 1259.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23100 and Loss: 0.6931478381156921\n",
      "Epoch: 23200 and Loss: 0.6931478381156921\n",
      "Epoch: 23300 and Loss: 0.6931478381156921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  24%|██▎       | 23589/100000 [00:19<01:02, 1220.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23400 and Loss: 0.6931478381156921\n",
      "Epoch: 23500 and Loss: 0.6931478381156921\n",
      "Epoch: 23600 and Loss: 0.6931478381156921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  24%|██▍       | 23861/100000 [00:19<00:59, 1287.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23700 and Loss: 0.6931478381156921\n",
      "Epoch: 23800 and Loss: 0.6931478381156921\n",
      "Epoch: 23900 and Loss: 0.6931478381156921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  24%|██▍       | 24260/100000 [00:20<00:57, 1308.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24000 and Loss: 0.6931478381156921\n",
      "Epoch: 24100 and Loss: 0.6931478381156921\n",
      "Epoch: 24200 and Loss: 0.6931478381156921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  25%|██▍       | 24530/100000 [00:20<00:57, 1323.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24300 and Loss: 0.6931478381156921\n",
      "Epoch: 24400 and Loss: 0.6931478381156921\n",
      "Epoch: 24500 and Loss: 0.6931478381156921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  25%|██▍       | 24793/100000 [00:20<00:58, 1294.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24600 and Loss: 0.6931478381156921\n",
      "Epoch: 24700 and Loss: 0.6931478381156921\n",
      "Epoch: 24800 and Loss: 0.6931478381156921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  25%|██▌       | 25062/100000 [00:20<00:56, 1316.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24900 and Loss: 0.6931478381156921\n",
      "Epoch: 25000 and Loss: 0.6931478381156921\n",
      "Epoch: 25100 and Loss: 0.6931478381156921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  25%|██▌       | 25330/100000 [00:20<00:57, 1293.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25200 and Loss: 0.6931478381156921\n",
      "Epoch: 25300 and Loss: 0.6931478381156921\n",
      "Epoch: 25400 and Loss: 0.6931478381156921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  26%|██▌       | 25723/100000 [00:21<00:57, 1287.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25500 and Loss: 0.6931478381156921\n",
      "Epoch: 25600 and Loss: 0.6931478381156921\n",
      "Epoch: 25700 and Loss: 0.6931478381156921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  26%|██▌       | 25981/100000 [00:21<00:58, 1260.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25800 and Loss: 0.6931478381156921\n",
      "Epoch: 25900 and Loss: 0.6931478381156921\n",
      "Epoch: 26000 and Loss: 0.6931478381156921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  26%|██▌       | 26234/100000 [00:21<00:59, 1244.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26100 and Loss: 0.6931478381156921\n",
      "Epoch: 26200 and Loss: 0.6931478381156921\n",
      "Epoch: 26300 and Loss: 0.6931478381156921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  27%|██▋       | 26618/100000 [00:21<00:58, 1251.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26400 and Loss: 0.6931478381156921\n",
      "Epoch: 26500 and Loss: 0.6931478381156921\n",
      "Epoch: 26600 and Loss: 0.6931478381156921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  27%|██▋       | 26876/100000 [00:22<00:58, 1242.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26700 and Loss: 0.6931478381156921\n",
      "Epoch: 26800 and Loss: 0.6931478381156921\n",
      "Epoch: 26900 and Loss: 0.6931478381156921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  27%|██▋       | 27241/100000 [00:22<01:01, 1179.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27000 and Loss: 0.6931478381156921\n",
      "Epoch: 27100 and Loss: 0.6931478381156921\n",
      "Epoch: 27200 and Loss: 0.6931478381156921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  27%|██▋       | 27492/100000 [00:22<00:59, 1211.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27300 and Loss: 0.6931478381156921\n",
      "Epoch: 27400 and Loss: 0.6931478381156921\n",
      "Epoch: 27500 and Loss: 0.6931478381156921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  28%|██▊       | 27739/100000 [00:22<01:00, 1199.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27600 and Loss: 0.6931478381156921\n",
      "Epoch: 27700 and Loss: 0.6931478381156921\n",
      "Epoch: 27800 and Loss: 0.6931478381156921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  28%|██▊       | 28117/100000 [00:23<00:58, 1225.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27900 and Loss: 0.6931478381156921\n",
      "Epoch: 28000 and Loss: 0.6931478381156921\n",
      "Epoch: 28100 and Loss: 0.6931478381156921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  28%|██▊       | 28373/100000 [00:23<00:57, 1250.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28200 and Loss: 0.6931478381156921\n",
      "Epoch: 28300 and Loss: 0.6931478381156921\n",
      "Epoch: 28400 and Loss: 0.6931478381156921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  29%|██▊       | 28737/100000 [00:23<00:58, 1216.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28500 and Loss: 0.6931478381156921\n",
      "Epoch: 28600 and Loss: 0.6931478381156921\n",
      "Epoch: 28700 and Loss: 0.6931478381156921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[10], line 15\u001B[0m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;66;03m# Calculate loss and do backpropagation\u001B[39;00m\n\u001B[0;32m     14\u001B[0m loss \u001B[38;5;241m=\u001B[39m critertion(target_pred, target_XOR)\n\u001B[1;32m---> 15\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[0;32m     17\u001B[0m \u001B[38;5;66;03m# Updating neural network parameters: w = w - learning_rate * gradient\u001B[39;00m\n\u001B[0;32m     18\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()    \n",
      "File \u001B[1;32mD:\\Python\\envs\\DataAnalysis\\Lib\\site-packages\\torch\\_tensor.py:492\u001B[0m, in \u001B[0;36mTensor.backward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    482\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    483\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[0;32m    484\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[0;32m    485\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    490\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[0;32m    491\u001B[0m     )\n\u001B[1;32m--> 492\u001B[0m torch\u001B[38;5;241m.\u001B[39mautograd\u001B[38;5;241m.\u001B[39mbackward(\n\u001B[0;32m    493\u001B[0m     \u001B[38;5;28mself\u001B[39m, gradient, retain_graph, create_graph, inputs\u001B[38;5;241m=\u001B[39minputs\n\u001B[0;32m    494\u001B[0m )\n",
      "File \u001B[1;32mD:\\Python\\envs\\DataAnalysis\\Lib\\site-packages\\torch\\autograd\\__init__.py:251\u001B[0m, in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[0;32m    246\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[0;32m    248\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[0;32m    249\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[0;32m    250\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[1;32m--> 251\u001B[0m Variable\u001B[38;5;241m.\u001B[39m_execution_engine\u001B[38;5;241m.\u001B[39mrun_backward(  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[0;32m    252\u001B[0m     tensors,\n\u001B[0;32m    253\u001B[0m     grad_tensors_,\n\u001B[0;32m    254\u001B[0m     retain_graph,\n\u001B[0;32m    255\u001B[0m     create_graph,\n\u001B[0;32m    256\u001B[0m     inputs,\n\u001B[0;32m    257\u001B[0m     allow_unreachable\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[0;32m    258\u001B[0m     accumulate_grad\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[0;32m    259\u001B[0m )\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "input = X\n",
    "all_losses = []\n",
    "current_loss = 0\n",
    "plot_every = 100\n",
    "for epoch in tqdm(range(100000), desc=\"Training\"):\n",
    "    \n",
    "    # Zero the gradients\n",
    "    optimizer.zero_grad()    \n",
    "\n",
    "    # Forward pass to get output/logits\n",
    "    target_pred = ffnn.feed_forward(input)\n",
    "    \n",
    "    # Calculate loss and do backpropagation\n",
    "    loss = critertion(target_pred, target_XOR)\n",
    "    loss.backward()\n",
    "    \n",
    "    # Updating neural network parameters: w = w - learning_rate * gradient\n",
    "    optimizer.step()    \n",
    "    current_loss += loss\n",
    "    if epoch % plot_every == 0:\n",
    "        all_losses.append(current_loss / plot_every)\n",
    "        current_loss = 0\n",
    "        print('Epoch: {} and Loss: {}'.format(epoch, loss))\n",
    "\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T19:33:51.575424300Z",
     "start_time": "2023-11-05T19:33:27.138442600Z"
    }
   },
   "id": "b89e0d985c5ed46e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "P"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b656b0ed2e147ab0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
