{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d3b7bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from GD_class import GradientDescent\n",
    "import autograd.numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3adc8241",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_design_matrix(x, degree):\n",
    "    \"Creates the design matrix for the given polynomial degree and input data\"\n",
    "    \n",
    "    X = np.zeros((len(x), degree+1))\n",
    "    \n",
    "    for i in range(X.shape[1]):\n",
    "        X[:,i] = np.power(x, i)\n",
    "        \n",
    "    return X\n",
    "\n",
    "def cost_function_OLS(X, y, beta):\n",
    "    return (1.0/n)*np.sum((y-X.dot(beta))**2)\n",
    "\n",
    "def analytical_gradient(X, y, beta):\n",
    "    return (2.0/n)*np.dot(X.T, ((np.dot(X,beta))-y))\n",
    "\n",
    "np.random.seed(1342)\n",
    "\n",
    "true_beta = [2, 0.5, 3.2]\n",
    "\n",
    "n = 100\n",
    "\n",
    "x = np.linspace(0, 1, n)\n",
    "y = np.sum(np.asarray([x ** p * b for p, b in enumerate(true_beta)]),\n",
    "                axis=0) + 0.1 * np.random.normal(size=len(x))\n",
    "\n",
    "# Making a design matrix to use for linear regression part\n",
    "degree = 2\n",
    "X = make_design_matrix(x, degree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dacdcadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "tol=1e-3\n",
    "beta_guess = np.random.rand(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44fe763a",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m grad_descent \u001b[38;5;241m=\u001b[39m GradientDescent(X, y, learning_rate, tol, cost_function_OLS)\n\u001b[0;32m      3\u001b[0m max_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100000\u001b[39m\n\u001b[1;32m----> 4\u001b[0m beta_calculated \u001b[38;5;241m=\u001b[39m \u001b[43mgrad_descent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(beta_calculated)\n",
      "File \u001b[1;32m~\\FYS_STK_4155\\Projects\\Project 2\\GD_class.py:50\u001b[0m, in \u001b[0;36mGradientDescent.iterate\u001b[1;34m(self, max_iter)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miteration \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_iter):\n\u001b[1;32m---> 50\u001b[0m     gradient \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalc_gradient\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_convergence(gradient, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miteration):\n\u001b[0;32m     53\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\fysstk4155\\lib\\site-packages\\autograd\\wrap_util.py:20\u001b[0m, in \u001b[0;36munary_to_nary.<locals>.nary_operator.<locals>.nary_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     19\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(args[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m argnum)\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m unary_operator(unary_f, x, \u001b[38;5;241m*\u001b[39mnary_op_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mnary_op_kwargs)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\fysstk4155\\lib\\site-packages\\autograd\\differential_operators.py:32\u001b[0m, in \u001b[0;36mgrad\u001b[1;34m(fun, x)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m vspace(ans)\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGrad only applies to real scalar-output functions. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     31\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTry jacobian, elementwise_grad or holomorphic_grad.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 32\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvjp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvspace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mans\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\fysstk4155\\lib\\site-packages\\autograd\\core.py:14\u001b[0m, in \u001b[0;36mmake_vjp.<locals>.vjp\u001b[1;34m(g)\u001b[0m\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvjp\u001b[39m(g): \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbackward_pass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_node\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\fysstk4155\\lib\\site-packages\\autograd\\core.py:23\u001b[0m, in \u001b[0;36mbackward_pass\u001b[1;34m(g, end_node)\u001b[0m\n\u001b[0;32m     21\u001b[0m     ingrads \u001b[38;5;241m=\u001b[39m node\u001b[38;5;241m.\u001b[39mvjp(outgrad[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m parent, ingrad \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(node\u001b[38;5;241m.\u001b[39mparents, ingrads):\n\u001b[1;32m---> 23\u001b[0m         outgrads[parent] \u001b[38;5;241m=\u001b[39m \u001b[43madd_outgrads\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutgrads\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparent\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mingrad\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outgrad[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\fysstk4155\\lib\\site-packages\\autograd\\core.py:167\u001b[0m, in \u001b[0;36madd_outgrads\u001b[1;34m(prev_g_flagged, g)\u001b[0m\n\u001b[0;32m    165\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m sparse_add(vs, prev_g, g), \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 167\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmut_add\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprev_g\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mg\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    169\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sparse:\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\fysstk4155\\lib\\site-packages\\autograd\\tracer.py:37\u001b[0m, in \u001b[0;36mprimitive.<locals>.f_wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f_raw)\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mf_wrapped\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 37\u001b[0m     boxed_args, trace, node_constructor \u001b[38;5;241m=\u001b[39m \u001b[43mfind_top_boxed_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m boxed_args:\n\u001b[0;32m     39\u001b[0m         argvals \u001b[38;5;241m=\u001b[39m subvals(args, [(argnum, box\u001b[38;5;241m.\u001b[39m_value) \u001b[38;5;28;01mfor\u001b[39;00m argnum, box \u001b[38;5;129;01min\u001b[39;00m boxed_args])\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\fysstk4155\\lib\\site-packages\\autograd\\tracer.py:70\u001b[0m, in \u001b[0;36mfind_top_boxed_args\u001b[1;34m(args)\u001b[0m\n\u001b[0;32m     68\u001b[0m top_node_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m argnum, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(args):\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43misbox\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     71\u001b[0m         trace \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39m_trace\n\u001b[0;32m     72\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m trace \u001b[38;5;241m>\u001b[39m top_trace:\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\fysstk4155\\lib\\site-packages\\autograd\\tracer.py:123\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    120\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt differentiate w.r.t. type \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mtype\u001b[39m(value)))\n\u001b[0;32m    122\u001b[0m box_types \u001b[38;5;241m=\u001b[39m Box\u001b[38;5;241m.\u001b[39mtypes\n\u001b[1;32m--> 123\u001b[0m isbox  \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01min\u001b[39;00m box_types  \u001b[38;5;66;03m# almost 3X faster than isinstance(x, Box)\u001b[39;00m\n\u001b[0;32m    124\u001b[0m getval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: getval(x\u001b[38;5;241m.\u001b[39m_value) \u001b[38;5;28;01mif\u001b[39;00m isbox(x) \u001b[38;5;28;01melse\u001b[39;00m x\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "np.random.seed(1342)\n",
    "grad_descent = GradientDescent(X, y, learning_rate, tol, cost_function_OLS)\n",
    "max_iter = 100000\n",
    "beta_calculated = grad_descent.iterate(max_iter)\n",
    "print(beta_calculated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4db1ede3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'GradientDescentMomentum' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(\u001b[38;5;241m1342\u001b[39m)\n\u001b[0;32m      2\u001b[0m momentum\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m\n\u001b[1;32m----> 3\u001b[0m grad_descent_m \u001b[38;5;241m=\u001b[39m \u001b[43mGradientDescentMomentum\u001b[49m(momentum, X\u001b[38;5;241m=\u001b[39mX, y\u001b[38;5;241m=\u001b[39my, \n\u001b[0;32m      4\u001b[0m                                          learning_rate\u001b[38;5;241m=\u001b[39mlearning_rate, tol\u001b[38;5;241m=\u001b[39mtol, \n\u001b[0;32m      5\u001b[0m                                          cost_function\u001b[38;5;241m=\u001b[39mcost_function_OLS)\n\u001b[0;32m      6\u001b[0m max_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100000\u001b[39m\n\u001b[0;32m      7\u001b[0m beta_calculated \u001b[38;5;241m=\u001b[39m grad_descent\u001b[38;5;241m.\u001b[39miterate(max_iter)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'GradientDescentMomentum' is not defined"
     ]
    }
   ],
   "source": [
    "np.random.seed(1342)\n",
    "momentum=0.3\n",
    "grad_descent_m = GradientDescentMomentum(momentum, X=X, y=y, \n",
    "                                         learning_rate=learning_rate, tol=tol, \n",
    "                                         cost_function=cost_function_OLS)\n",
    "max_iter = 100000\n",
    "beta_calculated = grad_descent_m.iterate(max_iter)\n",
    "print(beta_calculated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102b9322",
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_descent = GradientDescent(X, y, learning_rate, tol, cost_function_OLS, analytic_gradient=analytical_gradient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a1df8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4d64870a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-5.35380067, -3.19965551, -2.34540333])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_descent = GradientDescent(X, y, learning_rate, tol, cost_function_OLS)\n",
    "grad_descent.cost_gradient(X, y, beta_guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "226d736b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-5.35380067, -3.19965551, -2.34540333])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_descent = GradientDescent(X, y, learning_rate, tol, cost_function_OLS, analytic_gradient=analytical_gradient)\n",
    "grad_descent.cost_gradient(X, y, beta_guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fd649c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2d70e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
